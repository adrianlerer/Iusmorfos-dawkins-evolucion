{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Diagnostics and Model Validation\n",
    "## Iusmorfos Framework - Advanced Statistical Testing\n",
    "\n",
    "**Author**: Iusmorfos Research Team  \n",
    "**Date**: 2024  \n",
    "**Version**: 1.0\n",
    "\n",
    "This notebook provides comprehensive statistical diagnostics and model validation for the Iusmorfos framework, including robustness testing, regression diagnostics, and power-law validation.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Configuration](#setup)\n",
    "2. [Bootstrap Robustness Testing](#bootstrap)\n",
    "3. [Power-Law Distribution Validation](#power-law)\n",
    "4. [Regression Diagnostics](#regression)\n",
    "5. [Cross-Validation Analysis](#cross-validation)\n",
    "6. [Sensitivity Analysis](#sensitivity)\n",
    "7. [Outlier Detection and Impact](#outliers)\n",
    "8. [Model Comparison and Selection](#model-comparison)\n",
    "9. [Statistical Assumptions Testing](#assumptions)\n",
    "10. [Reproducibility Validation](#reproducibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path('../src').resolve()))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import powerlaw, pareto, norm, kstest, anderson\n",
    "from scipy.optimize import minimize\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan, het_white\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "from config import get_config\n",
    "from robustness import IusmorfosRobustnessAnalyzer\n",
    "\n",
    "# Plotting configuration\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"üî¨ Statistical Diagnostics Notebook Initialized\")\n",
    "print(f\"üìä Timestamp: {pd.Timestamp.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration {#setup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize configuration and load data\n",
    "config = get_config()\n",
    "print(f\"üîß Configuration loaded: {config}\")\n",
    "\n",
    "# Initialize robustness analyzer\n",
    "robustness_analyzer = IusmorfosRobustnessAnalyzer(n_bootstrap=1000)\n",
    "print(f\"üî¨ Robustness analyzer initialized\")\n",
    "\n",
    "# Create or load sample data for statistical testing\n",
    "np.random.seed(42)  # Ensure reproducibility\n",
    "\n",
    "# Generate realistic legal innovation data for testing\n",
    "n_samples = 842  # Argentina's documented innovations\n",
    "\n",
    "# Complexity scores (1-10, beta distribution)\n",
    "complexity_data = np.random.beta(2, 3, n_samples) * 9 + 1\n",
    "\n",
    "# Citation counts (power-law distribution with Œ≥ ‚âà 2.3)\n",
    "citation_data = np.random.pareto(1.3, n_samples) * 2\n",
    "citation_data = np.clip(citation_data, 0, 200).astype(int)\n",
    "\n",
    "# Adoption success (0-1, beta distribution)\n",
    "adoption_data = np.random.beta(3, 2, n_samples)\n",
    "\n",
    "# Implementation time (months, lognormal)\n",
    "implementation_time = np.random.lognormal(2.5, 0.8, n_samples)\n",
    "implementation_time = np.clip(implementation_time, 1, 120)\n",
    "\n",
    "# Years (temporal distribution)\n",
    "years = np.random.choice(range(1990, 2024), n_samples)\n",
    "\n",
    "# Create combined dataset\n",
    "test_data = pd.DataFrame({\n",
    "    'complexity': complexity_data,\n",
    "    'citations': citation_data,\n",
    "    'adoption_success': adoption_data,\n",
    "    'implementation_months': implementation_time,\n",
    "    'year': years\n",
    "})\n",
    "\n",
    "print(f\"\\nüìä Test Dataset Created:\")\n",
    "print(f\"Shape: {test_data.shape}\")\n",
    "print(f\"\\nDescriptive Statistics:\")\n",
    "print(test_data.describe().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bootstrap Robustness Testing {#bootstrap}\n",
    "\n",
    "Test the robustness of key statistics using bootstrap resampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üß™ BOOTSTRAP ROBUSTNESS TESTING\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Test complexity statistics\n",
    "complexity_results = robustness_analyzer.test_complexity_evolution_robustness(\n",
    "    test_data['complexity'].values\n",
    ")\n",
    "\n",
    "# Test citation network statistics\n",
    "citation_results = robustness_analyzer.test_citation_network_robustness(\n",
    "    test_data['citations'].values\n",
    ")\n",
    "\n",
    "# Test adoption success statistics\n",
    "adoption_results = robustness_analyzer.test_adoption_success_robustness(\n",
    "    test_data['adoption_success'].values\n",
    ")\n",
    "\n",
    "# Display results summary\n",
    "print(f\"\\nüìä Bootstrap Results Summary:\")\n",
    "all_results = {**complexity_results, **citation_results, **adoption_results}\n",
    "\n",
    "robust_tests = sum(1 for result in all_results.values() if result.robust)\n",
    "total_tests = len(all_results)\n",
    "\n",
    "print(f\"Total tests: {total_tests}\")\n",
    "print(f\"Robust tests: {robust_tests}\")\n",
    "print(f\"Robustness rate: {robust_tests/total_tests:.1%}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Robust Statistics:\")\n",
    "for name, result in all_results.items():\n",
    "    if result.robust:\n",
    "        print(f\"  ‚Ä¢ {result.test_name}: {result.original_value:.4f} ¬± {result.bootstrap_std:.4f}\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è Unstable Statistics:\")\n",
    "for name, result in all_results.items():\n",
    "    if not result.robust:\n",
    "        print(f\"  ‚Ä¢ {result.test_name}: {result.original_value:.4f} (p={result.p_value:.4f})\")\n",
    "\n",
    "# Plot bootstrap distributions\n",
    "robustness_analyzer.plot_bootstrap_distributions(save_plots=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Power-Law Distribution Validation {#power-law}\n",
    "\n",
    "Validate the power-law hypothesis for citation distributions (Œ≥=2.3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä POWER-LAW DISTRIBUTION VALIDATION\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "citations = test_data['citations'].values\n",
    "citations_nonzero = citations[citations > 0]\n",
    "\n",
    "print(f\"Citation data: {len(citations)} total, {len(citations_nonzero)} non-zero\")\n",
    "\n",
    "# Create comprehensive power-law analysis plots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Citation distribution histogram\n",
    "axes[0, 0].hist(citations, bins=50, alpha=0.7, edgecolor='black', color='skyblue')\n",
    "axes[0, 0].set_title('Citation Count Distribution')\n",
    "axes[0, 0].set_xlabel('Citations')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_yscale('log')\n",
    "\n",
    "# 2. Log-log plot for power-law fitting\n",
    "if len(citations_nonzero) > 1:\n",
    "    # Calculate frequency of each citation count\n",
    "    unique_citations, counts = np.unique(citations_nonzero, return_counts=True)\n",
    "    \n",
    "    # Log-log plot\n",
    "    axes[0, 1].loglog(unique_citations, counts, 'bo-', alpha=0.6, label='Data')\n",
    "    \n",
    "    # Fit power-law\n",
    "    log_x = np.log(unique_citations)\n",
    "    log_y = np.log(counts)\n",
    "    \n",
    "    if len(log_x) > 1:\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(log_x, log_y)\n",
    "        gamma_estimated = -slope\n",
    "        \n",
    "        # Plot fitted line\n",
    "        x_fit = np.linspace(unique_citations.min(), unique_citations.max(), 100)\n",
    "        y_fit = np.exp(intercept) * x_fit ** slope\n",
    "        axes[0, 1].loglog(x_fit, y_fit, 'r--', alpha=0.8, \n",
    "                         label=f'Œ≥ = {gamma_estimated:.3f} (R¬≤ = {r_value**2:.3f})')\n",
    "        \n",
    "        axes[0, 1].set_title('Log-Log Plot (Power-Law Fit)')\n",
    "        axes[0, 1].set_xlabel('Citation Count (log)')\n",
    "        axes[0, 1].set_ylabel('Frequency (log)')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True)\n",
    "        \n",
    "        # Print power-law analysis results\n",
    "        print(f\"\\nüîç Power-Law Analysis Results:\")\n",
    "        print(f\"Estimated Œ≥: {gamma_estimated:.3f}\")\n",
    "        print(f\"Expected Œ≥ (Iusmorfos): 2.3\")\n",
    "        print(f\"Difference from expected: {abs(gamma_estimated - 2.3):.3f}\")\n",
    "        print(f\"Goodness of fit (R¬≤): {r_value**2:.3f}\")\n",
    "        print(f\"Statistical significance (p): {p_value:.4f}\")\n",
    "        \n",
    "        if abs(gamma_estimated - 2.3) < 0.5:\n",
    "            print(\"‚úÖ Close to expected Œ≥=2.3\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Deviates from expected Œ≥=2.3\")\n",
    "\n",
    "# 3. Cumulative distribution (CCDF)\n",
    "sorted_citations = np.sort(citations_nonzero)\n",
    "ccdf = 1 - np.arange(len(sorted_citations)) / len(sorted_citations)\n",
    "\n",
    "axes[0, 2].loglog(sorted_citations, ccdf, 'go-', alpha=0.6, label='Empirical CCDF')\n",
    "\n",
    "# Theoretical power-law CCDF\n",
    "if 'gamma_estimated' in locals():\n",
    "    x_min = sorted_citations[0]\n",
    "    theoretical_ccdf = (sorted_citations / x_min) ** (-(gamma_estimated - 1))\n",
    "    axes[0, 2].loglog(sorted_citations, theoretical_ccdf, 'r--', \n",
    "                     label=f'Power-law (Œ≥={gamma_estimated:.2f})')\n",
    "\n",
    "axes[0, 2].set_title('Cumulative Distribution (CCDF)')\n",
    "axes[0, 2].set_xlabel('Citation Count (log)')\n",
    "axes[0, 2].set_ylabel('P(X ‚â• x) (log)')\n",
    "axes[0, 2].legend()\n",
    "axes[0, 2].grid(True)\n",
    "\n",
    "# 4. Rank-frequency plot (Zipf's law)\n",
    "ranks = np.arange(1, len(sorted_citations) + 1)\n",
    "sorted_desc = sorted_citations[::-1]\n",
    "\n",
    "axes[1, 0].loglog(ranks, sorted_desc, 'mo-', alpha=0.6, label='Rank-frequency')\n",
    "axes[1, 0].set_title('Rank-Frequency Plot (Zipf\\'s Law)')\n",
    "axes[1, 0].set_xlabel('Rank (log)')\n",
    "axes[1, 0].set_ylabel('Citation Count (log)')\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# 5. Q-Q plot against theoretical power-law\n",
    "if len(citations_nonzero) > 10:\n",
    "    # Fit power-law using scipy\n",
    "    try:\n",
    "        fitted_params = powerlaw.fit(citations_nonzero)\n",
    "        theoretical_quantiles = powerlaw.ppf(np.linspace(0.01, 0.99, len(citations_nonzero)), \n",
    "                                           *fitted_params)\n",
    "        \n",
    "        axes[1, 1].scatter(np.sort(theoretical_quantiles), np.sort(citations_nonzero), \n",
    "                          alpha=0.6, s=20)\n",
    "        \n",
    "        # Perfect fit line\n",
    "        min_val = min(np.min(theoretical_quantiles), np.min(citations_nonzero))\n",
    "        max_val = max(np.max(theoretical_quantiles), np.max(citations_nonzero))\n",
    "        axes[1, 1].plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8)\n",
    "        \n",
    "        axes[1, 1].set_title('Q-Q Plot: Power-Law')\n",
    "        axes[1, 1].set_xlabel('Theoretical Quantiles')\n",
    "        axes[1, 1].set_ylabel('Sample Quantiles')\n",
    "        axes[1, 1].grid(True)\n",
    "        \n",
    "    except Exception as e:\n",
    "        axes[1, 1].text(0.5, 0.5, f'Q-Q plot failed: {str(e)}', \n",
    "                        transform=axes[1, 1].transAxes, ha='center')\n",
    "\n",
    "# 6. Goodness-of-fit tests\n",
    "if len(citations_nonzero) > 10:\n",
    "    # Kolmogorov-Smirnov test\n",
    "    try:\n",
    "        ks_stat, ks_p = kstest(citations_nonzero, lambda x: powerlaw.cdf(x, *fitted_params))\n",
    "        \n",
    "        # Anderson-Darling test (if available)\n",
    "        try:\n",
    "            ad_result = anderson(citations_nonzero, dist='norm')  # Note: limited distributions in scipy\n",
    "            ad_stat = ad_result.statistic\n",
    "        except:\n",
    "            ad_stat = np.nan\n",
    "        \n",
    "        # Display test results\n",
    "        test_results = f\"\"\"Goodness-of-Fit Tests:\n",
    "        \n",
    "Kolmogorov-Smirnov:\n",
    "  Statistic: {ks_stat:.4f}\n",
    "  p-value: {ks_p:.4f}\n",
    "  {'‚úÖ Fits power-law' if ks_p > 0.05 else '‚ùå Rejects power-law'}\n",
    "  \n",
    "Power-law Parameters:\n",
    "  Shape (a): {fitted_params[0]:.3f}\n",
    "  Location: {fitted_params[1]:.3f}\n",
    "  Scale: {fitted_params[2]:.3f}\n",
    "        \"\"\"\n",
    "        \n",
    "        axes[1, 2].text(0.05, 0.95, test_results, transform=axes[1, 2].transAxes, \n",
    "                        fontsize=10, verticalalignment='top', fontfamily='monospace')\n",
    "        axes[1, 2].set_title('Statistical Test Results')\n",
    "        axes[1, 2].set_xticks([])\n",
    "        axes[1, 2].set_yticks([])\n",
    "        \n",
    "        print(f\"\\nüß™ Goodness-of-Fit Tests:\")\n",
    "        print(f\"Kolmogorov-Smirnov: D = {ks_stat:.4f}, p = {ks_p:.4f}\")\n",
    "        if ks_p > 0.05:\n",
    "            print(\"‚úÖ Data consistent with power-law distribution\")\n",
    "        else:\n",
    "            print(\"‚ùå Data rejects power-law distribution\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        axes[1, 2].text(0.5, 0.5, f'Statistical tests failed: {str(e)}', \n",
    "                        transform=axes[1, 2].transAxes, ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Network concentration analysis (Pareto principle)\n",
    "total_citations = np.sum(citations)\n",
    "sorted_desc_all = np.sort(citations)[::-1]\n",
    "cumsum_citations = np.cumsum(sorted_desc_all)\n",
    "\n",
    "# Find 80% threshold\n",
    "threshold_80 = 0.8 * total_citations\n",
    "pareto_80_index = np.where(cumsum_citations >= threshold_80)[0]\n",
    "\n",
    "if len(pareto_80_index) > 0:\n",
    "    pareto_80_pct = (pareto_80_index[0] + 1) / len(citations) * 100\n",
    "    print(f\"\\nüìä Network Concentration Analysis:\")\n",
    "    print(f\"80/20 Rule: Top {pareto_80_pct:.1f}% of innovations account for 80% of citations\")\n",
    "    \n",
    "    if pareto_80_pct <= 25:\n",
    "        print(\"‚úÖ Strong Pareto effect (heavy concentration)\")\n",
    "    elif pareto_80_pct <= 40:\n",
    "        print(\"üìä Moderate concentration\")\n",
    "    else:\n",
    "        print(\"üìà Weak concentration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Regression Diagnostics {#regression}\n",
    "\n",
    "Perform comprehensive regression diagnostics for model relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìà REGRESSION DIAGNOSTICS\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Create regression model: adoption_success ~ complexity + log(citations + 1) + implementation_time\n",
    "# Prepare data\n",
    "y = test_data['adoption_success'].values\n",
    "X_raw = test_data[['complexity', 'citations', 'implementation_months']].copy()\n",
    "X_raw['log_citations'] = np.log1p(X_raw['citations'])  # log(citations + 1)\n",
    "X_raw['log_implementation'] = np.log(X_raw['implementation_months'])\n",
    "\n",
    "# Select final features\n",
    "feature_cols = ['complexity', 'log_citations', 'log_implementation']\n",
    "X = X_raw[feature_cols].values\n",
    "\n",
    "# Add intercept for statsmodels\n",
    "X_sm = sm.add_constant(X)\n",
    "\n",
    "# Fit OLS model\n",
    "model = sm.OLS(y, X_sm).fit()\n",
    "\n",
    "print(f\"\\nüìä Regression Model Results:\")\n",
    "print(model.summary())\n",
    "\n",
    "# Extract predictions and residuals\n",
    "y_pred = model.fittedvalues\n",
    "residuals = model.resid\n",
    "standardized_residuals = residuals / np.std(residuals)\n",
    "\n",
    "# Create diagnostic plots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Residuals vs Fitted\n",
    "axes[0, 0].scatter(y_pred, residuals, alpha=0.6)\n",
    "axes[0, 0].axhline(y=0, color='r', linestyle='--')\n",
    "axes[0, 0].set_xlabel('Fitted Values')\n",
    "axes[0, 0].set_ylabel('Residuals')\n",
    "axes[0, 0].set_title('Residuals vs Fitted')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add LOWESS smoother\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "lowess_result = lowess(residuals, y_pred, frac=0.3)\n",
    "axes[0, 0].plot(lowess_result[:, 0], lowess_result[:, 1], 'orange', linewidth=2, label='LOWESS')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 2. Q-Q plot of residuals\n",
    "sm.qqplot(standardized_residuals, line='45', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Q-Q Plot of Residuals')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Scale-Location plot\n",
    "sqrt_abs_resid = np.sqrt(np.abs(standardized_residuals))\n",
    "axes[0, 2].scatter(y_pred, sqrt_abs_resid, alpha=0.6)\n",
    "axes[0, 2].set_xlabel('Fitted Values')\n",
    "axes[0, 2].set_ylabel('‚àö|Standardized Residuals|')\n",
    "axes[0, 2].set_title('Scale-Location Plot')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# LOWESS for scale-location\n",
    "lowess_sl = lowess(sqrt_abs_resid, y_pred, frac=0.3)\n",
    "axes[0, 2].plot(lowess_sl[:, 0], lowess_sl[:, 1], 'orange', linewidth=2)\n",
    "\n",
    "# 4. Residuals histogram\n",
    "axes[1, 0].hist(standardized_residuals, bins=30, alpha=0.7, density=True, edgecolor='black')\n",
    "axes[1, 0].set_xlabel('Standardized Residuals')\n",
    "axes[1, 0].set_ylabel('Density')\n",
    "axes[1, 0].set_title('Histogram of Residuals')\n",
    "\n",
    "# Overlay normal distribution\n",
    "x_norm = np.linspace(standardized_residuals.min(), standardized_residuals.max(), 100)\n",
    "y_norm = stats.norm.pdf(x_norm, 0, 1)\n",
    "axes[1, 0].plot(x_norm, y_norm, 'r-', linewidth=2, label='Normal(0,1)')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Leverage plot (Cook's distance)\n",
    "influence = model.get_influence()\n",
    "leverage = influence.hat_matrix_diag\n",
    "cooks_d = influence.cooks_distance[0]\n",
    "\n",
    "axes[1, 1].scatter(leverage, standardized_residuals, alpha=0.6, c=cooks_d, \n",
    "                  cmap='viridis', s=30)\n",
    "axes[1, 1].set_xlabel('Leverage')\n",
    "axes[1, 1].set_ylabel('Standardized Residuals')\n",
    "axes[1, 1].set_title('Residuals vs Leverage')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add Cook's distance contours\n",
    "p = X.shape[1] + 1  # number of parameters\n",
    "n = len(y)\n",
    "cooks_threshold = 4 / n\n",
    "axes[1, 1].axhline(y=2, color='r', linestyle='--', alpha=0.7, label='|res| = 2')\n",
    "axes[1, 1].axhline(y=-2, color='r', linestyle='--', alpha=0.7)\n",
    "axes[1, 1].legend()\n",
    "\n",
    "# 6. Actual vs Predicted\n",
    "axes[1, 2].scatter(y, y_pred, alpha=0.6)\n",
    "axes[1, 2].plot([y.min(), y.max()], [y.min(), y.max()], 'r--', linewidth=2)\n",
    "axes[1, 2].set_xlabel('Actual Values')\n",
    "axes[1, 2].set_ylabel('Predicted Values')\n",
    "axes[1, 2].set_title('Actual vs Predicted')\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# Add R¬≤ to the plot\n",
    "r2 = r2_score(y, y_pred)\n",
    "axes[1, 2].text(0.05, 0.95, f'R¬≤ = {r2:.3f}', transform=axes[1, 2].transAxes, \n",
    "               fontsize=12, verticalalignment='top', \n",
    "               bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical tests for assumptions\n",
    "print(f\"\\nüß™ REGRESSION ASSUMPTION TESTS:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# 1. Normality of residuals\n",
    "shapiro_stat, shapiro_p = stats.shapiro(standardized_residuals)\n",
    "jarque_stat, jarque_p = stats.jarque_bera(residuals)\n",
    "\n",
    "print(f\"\\n1. Normality of Residuals:\")\n",
    "print(f\"   Shapiro-Wilk: W = {shapiro_stat:.4f}, p = {shapiro_p:.4f}\")\n",
    "print(f\"   Jarque-Bera: JB = {jarque_stat:.4f}, p = {jarque_p:.4f}\")\n",
    "if shapiro_p > 0.05 and jarque_p > 0.05:\n",
    "    print(\"   ‚úÖ Residuals appear normally distributed\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Residuals may not be normally distributed\")\n",
    "\n",
    "# 2. Homoscedasticity (constant variance)\n",
    "bp_stat, bp_p, _, _ = het_breuschpagan(residuals, X_sm)\n",
    "white_stat, white_p, _, _ = het_white(residuals, X_sm)\n",
    "\n",
    "print(f\"\\n2. Homoscedasticity:\")\n",
    "print(f\"   Breusch-Pagan: LM = {bp_stat:.4f}, p = {bp_p:.4f}\")\n",
    "print(f\"   White test: LM = {white_stat:.4f}, p = {white_p:.4f}\")\n",
    "if bp_p > 0.05 and white_p > 0.05:\n",
    "    print(\"   ‚úÖ Homoscedasticity assumption satisfied\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Heteroscedasticity detected\")\n",
    "\n",
    "# 3. Independence (Durbin-Watson test)\n",
    "dw_stat = durbin_watson(residuals)\n",
    "print(f\"\\n3. Independence:\")\n",
    "print(f\"   Durbin-Watson: {dw_stat:.4f}\")\n",
    "if 1.5 < dw_stat < 2.5:\n",
    "    print(\"   ‚úÖ No evidence of autocorrelation\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Possible autocorrelation in residuals\")\n",
    "\n",
    "# 4. Multicollinearity (VIF)\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "print(f\"\\n4. Multicollinearity (VIF):\")\n",
    "for i in range(1, X_sm.shape[1]):  # Skip intercept\n",
    "    vif = variance_inflation_factor(X_sm, i)\n",
    "    feature_name = ['Complexity', 'Log Citations', 'Log Implementation'][i-1]\n",
    "    print(f\"   {feature_name}: VIF = {vif:.2f}\")\n",
    "    \n",
    "max_vif = max([variance_inflation_factor(X_sm, i) for i in range(1, X_sm.shape[1])])\n",
    "if max_vif < 5:\n",
    "    print(f\"   ‚úÖ Low multicollinearity (max VIF = {max_vif:.2f})\")\n",
    "elif max_vif < 10:\n",
    "    print(f\"   ‚ö†Ô∏è Moderate multicollinearity (max VIF = {max_vif:.2f})\")\n",
    "else:\n",
    "    print(f\"   ‚ùå High multicollinearity (max VIF = {max_vif:.2f})\")\n",
    "\n",
    "# 5. Outliers and influential points\n",
    "high_leverage = leverage > (2 * p / n)  # Rule of thumb: 2p/n\n",
    "high_cooks = cooks_d > cooks_threshold\n",
    "outlier_residuals = np.abs(standardized_residuals) > 3\n",
    "\n",
    "print(f\"\\n5. Outliers and Influential Points:\")\n",
    "print(f\"   High leverage points: {np.sum(high_leverage)} ({np.sum(high_leverage)/n:.1%})\")\n",
    "print(f\"   High Cook's distance: {np.sum(high_cooks)} ({np.sum(high_cooks)/n:.1%})\")\n",
    "print(f\"   Outlier residuals (|z| > 3): {np.sum(outlier_residuals)} ({np.sum(outlier_residuals)/n:.1%})\")\n",
    "\n",
    "if np.sum(high_cooks) < 0.05 * n:\n",
    "    print(\"   ‚úÖ Few influential points detected\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Multiple influential points detected\")\n",
    "\n",
    "# Model performance summary\n",
    "print(f\"\\nüìä MODEL PERFORMANCE SUMMARY:\")\n",
    "print(f\"R-squared: {model.rsquared:.4f}\")\n",
    "print(f\"Adjusted R-squared: {model.rsquared_adj:.4f}\")\n",
    "print(f\"F-statistic: {model.fvalue:.4f} (p = {model.f_pvalue:.4f})\")\n",
    "print(f\"AIC: {model.aic:.2f}\")\n",
    "print(f\"BIC: {model.bic:.2f}\")\n",
    "print(f\"Root MSE: {np.sqrt(model.mse_resid):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cross-Validation Analysis {#cross-validation}\n",
    "\n",
    "Perform cross-validation to assess model stability and generalizability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÑ CROSS-VALIDATION ANALYSIS\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_validate, learning_curve\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Prepare data for scikit-learn\n",
    "X_cv = X  # Features without intercept for sklearn\n",
    "y_cv = y\n",
    "\n",
    "# Initialize model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Define cross-validation strategy\n",
    "cv_folds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation with multiple metrics\n",
    "cv_scores = cross_validate(\n",
    "    lr_model, X_cv, y_cv, cv=cv_folds,\n",
    "    scoring=['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error'],\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Calculate additional metrics\n",
    "test_r2 = cv_scores['test_r2']\n",
    "train_r2 = cv_scores['train_r2']\n",
    "test_mse = -cv_scores['test_neg_mean_squared_error']\n",
    "train_mse = -cv_scores['train_neg_mean_squared_error']\n",
    "test_mae = -cv_scores['test_neg_mean_absolute_error']\n",
    "train_mae = -cv_scores['train_neg_mean_absolute_error']\n",
    "\n",
    "# Display cross-validation results\n",
    "print(f\"\\nüìä Cross-Validation Results (5-fold):\")\n",
    "print(f\"\\nR¬≤ Score:\")\n",
    "print(f\"  Training:   {train_r2.mean():.4f} ¬± {train_r2.std():.4f}\")\n",
    "print(f\"  Test:       {test_r2.mean():.4f} ¬± {test_r2.std():.4f}\")\n",
    "print(f\"  Difference: {(train_r2.mean() - test_r2.mean()):.4f}\")\n",
    "\n",
    "print(f\"\\nMean Squared Error:\")\n",
    "print(f\"  Training:   {train_mse.mean():.6f} ¬± {train_mse.std():.6f}\")\n",
    "print(f\"  Test:       {test_mse.mean():.6f} ¬± {test_mse.std():.6f}\")\n",
    "\n",
    "print(f\"\\nMean Absolute Error:\")\n",
    "print(f\"  Training:   {train_mae.mean():.6f} ¬± {train_mae.std():.6f}\")\n",
    "print(f\"  Test:       {test_mae.mean():.6f} ¬± {test_mae.std():.6f}\")\n",
    "\n",
    "# Overfitting assessment\n",
    "r2_gap = train_r2.mean() - test_r2.mean()\n",
    "if r2_gap < 0.05:\n",
    "    overfitting_status = \"‚úÖ No significant overfitting\"\n",
    "elif r2_gap < 0.1:\n",
    "    overfitting_status = \"‚ö†Ô∏è Mild overfitting\"\n",
    "else:\n",
    "    overfitting_status = \"‚ùå Significant overfitting\"\n",
    "\n",
    "print(f\"\\nOverfitting Assessment: {overfitting_status} (gap = {r2_gap:.4f})\")\n",
    "\n",
    "# Cross-validation stability\n",
    "cv_stability = test_r2.std() / test_r2.mean() if test_r2.mean() != 0 else np.inf\n",
    "if cv_stability < 0.1:\n",
    "    stability_status = \"‚úÖ High stability\"\n",
    "elif cv_stability < 0.2:\n",
    "    stability_status = \"üìä Moderate stability\"\n",
    "else:\n",
    "    stability_status = \"‚ö†Ô∏è Low stability\"\n",
    "\n",
    "print(f\"Cross-validation stability: {stability_status} (CV = {cv_stability:.3f})\")\n",
    "\n",
    "# Create cross-validation visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. R¬≤ scores across folds\n",
    "folds = range(1, 6)\n",
    "axes[0, 0].plot(folds, train_r2, 'bo-', label='Training', linewidth=2, markersize=8)\n",
    "axes[0, 0].plot(folds, test_r2, 'ro-', label='Validation', linewidth=2, markersize=8)\n",
    "axes[0, 0].fill_between(folds, train_r2, alpha=0.3, color='blue')\n",
    "axes[0, 0].fill_between(folds, test_r2, alpha=0.3, color='red')\n",
    "axes[0, 0].set_xlabel('Fold')\n",
    "axes[0, 0].set_ylabel('R¬≤ Score')\n",
    "axes[0, 0].set_title('R¬≤ Scores Across Folds')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. MSE across folds\n",
    "axes[0, 1].plot(folds, train_mse, 'bo-', label='Training', linewidth=2, markersize=8)\n",
    "axes[0, 1].plot(folds, test_mse, 'ro-', label='Validation', linewidth=2, markersize=8)\n",
    "axes[0, 1].set_xlabel('Fold')\n",
    "axes[0, 1].set_ylabel('Mean Squared Error')\n",
    "axes[0, 1].set_title('MSE Across Folds')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Learning curves\n",
    "train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "train_sizes_abs, train_scores_lc, val_scores_lc = learning_curve(\n",
    "    lr_model, X_cv, y_cv, cv=5, train_sizes=train_sizes, \n",
    "    scoring='r2', random_state=42\n",
    ")\n",
    "\n",
    "train_mean = train_scores_lc.mean(axis=1)\n",
    "train_std = train_scores_lc.std(axis=1)\n",
    "val_mean = val_scores_lc.mean(axis=1)\n",
    "val_std = val_scores_lc.std(axis=1)\n",
    "\n",
    "axes[1, 0].plot(train_sizes_abs, train_mean, 'bo-', label='Training Score')\n",
    "axes[1, 0].fill_between(train_sizes_abs, train_mean - train_std, \n",
    "                       train_mean + train_std, alpha=0.3, color='blue')\n",
    "axes[1, 0].plot(train_sizes_abs, val_mean, 'ro-', label='Validation Score')\n",
    "axes[1, 0].fill_between(train_sizes_abs, val_mean - val_std, \n",
    "                       val_mean + val_std, alpha=0.3, color='red')\n",
    "axes[1, 0].set_xlabel('Training Set Size')\n",
    "axes[1, 0].set_ylabel('R¬≤ Score')\n",
    "axes[1, 0].set_title('Learning Curves')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Prediction intervals across folds\n",
    "all_predictions = []\n",
    "all_actuals = []\n",
    "\n",
    "for train_idx, test_idx in cv_folds.split(X_cv):\n",
    "    X_train_fold, X_test_fold = X_cv[train_idx], X_cv[test_idx]\n",
    "    y_train_fold, y_test_fold = y_cv[train_idx], y_cv[test_idx]\n",
    "    \n",
    "    fold_model = LinearRegression().fit(X_train_fold, y_train_fold)\n",
    "    y_pred_fold = fold_model.predict(X_test_fold)\n",
    "    \n",
    "    all_predictions.extend(y_pred_fold)\n",
    "    all_actuals.extend(y_test_fold)\n",
    "\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_actuals = np.array(all_actuals)\n",
    "\n",
    "axes[1, 1].scatter(all_actuals, all_predictions, alpha=0.6, s=30)\n",
    "axes[1, 1].plot([all_actuals.min(), all_actuals.max()], \n",
    "               [all_actuals.min(), all_actuals.max()], 'r--', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Actual Values')\n",
    "axes[1, 1].set_ylabel('Predicted Values')\n",
    "axes[1, 1].set_title('Cross-Validated Predictions')\n",
    "\n",
    "# Calculate and display overall CV R¬≤\n",
    "cv_r2_overall = r2_score(all_actuals, all_predictions)\n",
    "axes[1, 1].text(0.05, 0.95, f'CV R¬≤ = {cv_r2_overall:.3f}', \n",
    "               transform=axes[1, 1].transAxes, fontsize=12, \n",
    "               verticalalignment='top',\n",
    "               bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ Cross-validation analysis complete\")\n",
    "print(f\"Overall CV R¬≤: {cv_r2_overall:.4f}\")\n",
    "print(f\"Model appears {'stable' if cv_stability < 0.15 else 'unstable'} across different data splits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Reproducibility Validation {#reproducibility}\n",
    "\n",
    "Verify that results are reproducible with the same random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÑ REPRODUCIBILITY VALIDATION\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Function to run complete analysis\n",
    "def run_analysis_with_seed(seed):\n",
    "    \"\"\"Run complete analysis with given seed.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Generate data\n",
    "    n = 842\n",
    "    complexity = np.random.beta(2, 3, n) * 9 + 1\n",
    "    citations = np.random.pareto(1.3, n) * 2\n",
    "    citations = np.clip(citations, 0, 200).astype(int)\n",
    "    adoption = np.random.beta(3, 2, n)\n",
    "    \n",
    "    # Calculate key statistics\n",
    "    results = {\n",
    "        'complexity_mean': np.mean(complexity),\n",
    "        'complexity_std': np.std(complexity),\n",
    "        'citations_mean': np.mean(citations),\n",
    "        'citations_max': np.max(citations),\n",
    "        'adoption_mean': np.mean(adoption),\n",
    "        'adoption_std': np.std(adoption)\n",
    "    }\n",
    "    \n",
    "    # Power-law analysis\n",
    "    citations_nz = citations[citations > 0]\n",
    "    if len(citations_nz) > 1:\n",
    "        unique_cit, counts = np.unique(citations_nz, return_counts=True)\n",
    "        if len(unique_cit) > 1:\n",
    "            log_x = np.log(unique_cit)\n",
    "            log_y = np.log(counts)\n",
    "            slope, intercept, r_val, p_val, std_err = stats.linregress(log_x, log_y)\n",
    "            results['power_law_gamma'] = -slope\n",
    "            results['power_law_r2'] = r_val**2\n",
    "        else:\n",
    "            results['power_law_gamma'] = 0\n",
    "            results['power_law_r2'] = 0\n",
    "    else:\n",
    "        results['power_law_gamma'] = 0\n",
    "        results['power_law_r2'] = 0\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test reproducibility with same seed\n",
    "print(\"üß™ Testing reproducibility with seed=42...\")\n",
    "\n",
    "results_1 = run_analysis_with_seed(42)\n",
    "results_2 = run_analysis_with_seed(42)\n",
    "results_3 = run_analysis_with_seed(42)\n",
    "\n",
    "# Check if results are identical\n",
    "reproducible = True\n",
    "tolerance = 1e-10\n",
    "\n",
    "print(f\"\\nüìä Reproducibility Test Results:\")\n",
    "for key in results_1.keys():\n",
    "    val_1 = results_1[key]\n",
    "    val_2 = results_2[key]\n",
    "    val_3 = results_3[key]\n",
    "    \n",
    "    diff_12 = abs(val_1 - val_2)\n",
    "    diff_13 = abs(val_1 - val_3)\n",
    "    diff_23 = abs(val_2 - val_3)\n",
    "    \n",
    "    max_diff = max(diff_12, diff_13, diff_23)\n",
    "    \n",
    "    if max_diff <= tolerance:\n",
    "        status = \"‚úÖ IDENTICAL\"\n",
    "    else:\n",
    "        status = \"‚ùå DIFFERENT\"\n",
    "        reproducible = False\n",
    "    \n",
    "    print(f\"{key:20s}: {val_1:10.6f} {status} (max diff: {max_diff:.2e})\")\n",
    "\n",
    "print(f\"\\nüéØ Overall Reproducibility: {'‚úÖ PASSED' if reproducible else '‚ùå FAILED'}\")\n",
    "\n",
    "# Test with different seeds to show variability\n",
    "print(f\"\\nüîÄ Testing variability with different seeds...\")\n",
    "\n",
    "seeds = [42, 123, 456, 789, 999]\n",
    "seed_results = []\n",
    "\n",
    "for seed in seeds:\n",
    "    result = run_analysis_with_seed(seed)\n",
    "    seed_results.append(result)\n",
    "\n",
    "# Calculate variability across seeds\n",
    "variability_df = pd.DataFrame(seed_results, index=[f'Seed_{s}' for s in seeds])\n",
    "\n",
    "print(f\"\\nüìà Variability Across Seeds:\")\n",
    "print(variability_df.round(4))\n",
    "\n",
    "# Calculate coefficient of variation for each statistic\n",
    "print(f\"\\nüìä Coefficient of Variation (CV) Across Seeds:\")\n",
    "for col in variability_df.columns:\n",
    "    mean_val = variability_df[col].mean()\n",
    "    std_val = variability_df[col].std()\n",
    "    cv = std_val / mean_val if mean_val != 0 else np.inf\n",
    "    print(f\"{col:20s}: CV = {cv:8.4f} ({'Low' if cv < 0.1 else 'Medium' if cv < 0.3 else 'High'} variability)\")\n",
    "\n",
    "# Visualize seed stability\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "key_stats = ['complexity_mean', 'citations_mean', 'adoption_mean', \n",
    "            'power_law_gamma', 'complexity_std', 'adoption_std']\n",
    "\n",
    "for i, stat in enumerate(key_stats):\n",
    "    if i < len(axes) and stat in variability_df.columns:\n",
    "        values = variability_df[stat].values\n",
    "        \n",
    "        axes[i].bar(range(len(seeds)), values, alpha=0.7, \n",
    "                   color=plt.cm.viridis(i/len(key_stats)))\n",
    "        axes[i].set_title(f'{stat.replace(\"_\", \" \").title()}')\n",
    "        axes[i].set_xlabel('Seed')\n",
    "        axes[i].set_ylabel('Value')\n",
    "        axes[i].set_xticks(range(len(seeds)))\n",
    "        axes[i].set_xticklabels(seeds, rotation=45)\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add mean line\n",
    "        mean_line = np.mean(values)\n",
    "        axes[i].axhline(y=mean_line, color='red', linestyle='--', alpha=0.8, \n",
    "                       label=f'Mean: {mean_line:.3f}')\n",
    "        axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Generate reproducibility report\n",
    "reproducibility_report = {\n",
    "    'timestamp': pd.Timestamp.now().isoformat(),\n",
    "    'reproducibility_passed': reproducible,\n",
    "    'tolerance_used': tolerance,\n",
    "    'seeds_tested': seeds,\n",
    "    'identical_results_with_same_seed': reproducible,\n",
    "    'variability_across_seeds': variability_df.std().to_dict(),\n",
    "    'mean_values': variability_df.mean().to_dict(),\n",
    "    'recommendations': [\n",
    "        \"Always use fixed random seeds for reproducible research\",\n",
    "        \"Report random seeds used in publications\",\n",
    "        \"Test robustness across multiple seeds\",\n",
    "        \"Document any sources of non-determinism\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Save reproducibility report\n",
    "report_path = config.get_path('results_dir') / f\"reproducibility_report_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "with open(report_path, 'w') as f:\n",
    "    json.dump(reproducibility_report, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\nüíæ Reproducibility report saved: {report_path}\")\n",
    "print(f\"\\n‚úÖ Statistical diagnostics notebook complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}