#!/usr/bin/env python3
"""
VALIDACI√ìN EMP√çRICA - BIOMORFOS LEGALES vs DATASET REAL

Valida los resultados del experimento de biomorfos legales contra el dataset
real de 842 innovaciones argentinas y datos multinacionales.

Author: AI Assistant (Genspark/Claude)  
Date: 2025-09-21
Version: 1.0 - Validaci√≥n Emp√≠rica
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Any, Tuple
import json
from sklearn.metrics import accuracy_score, classification_report
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
from biomorfos_legales_dawkins import GenLegal, Jusmorfo, SimuladorBiomorfosLegales

class ValidadorEmp√≠rico:
    """Valida biomorfos legales contra datos emp√≠ricos reales"""
    
    def __init__(self):
        self.datos_innovaciones = None
        self.sistemas_reales_codificados = {}
        self.m√©tricas_validaci√≥n = {}
        
        # Mapeo de innovaciones reales a coordenadas iuspace
        self.mapeo_innovaciones = {
            # Basado en el dataset real de innovations_exported.csv
            'Pesificacion Asimetrica': [6, 8, 7, 4, 3, 8, 9, 5, 4],
            'Amparo Constitutional': [5, 4, 6, 8, 3, 5, 4, 6, 3],
            'Fideicomiso Adaptation': [7, 5, 8, 7, 4, 6, 9, 7, 6],
            'UVA Inflation Adjustment': [8, 6, 7, 6, 5, 7, 9, 6, 7],
            'Corporate Criminal Liability': [8, 7, 9, 5, 8, 8, 8, 7, 6],
            'Fintech Regulatory Sandbox': [6, 5, 6, 7, 4, 5, 8, 8, 9],
            'Digital Identity Framework': [7, 6, 8, 6, 5, 6, 7, 7, 9],
            'Climate Litigation Framework': [5, 4, 7, 6, 4, 6, 6, 9, 7]
        }
    
    def cargar_datos_reales(self) -> bool:
        """Carga los datasets reales disponibles"""
        
        try:
            # Intentar cargar datos de innovaciones
            self.datos_innovaciones = pd.read_csv('/home/user/webapp/innovations_exported.csv')
            print(f"‚úÖ Dataset cargado: {len(self.datos_innovaciones)} innovaciones")
            
            # Procesar datos adicionales si est√°n disponibles
            archivos_adicionales = [
                '/home/user/webapp/evolution_cases.csv',
                '/home/user/webapp/velocity_metrics.csv',
                '/home/user/webapp/transplants_tracking.csv'
            ]
            
            for archivo in archivos_adicionales:
                try:
                    df_adicional = pd.read_csv(archivo)
                    print(f"‚úÖ Dataset adicional: {archivo.split('/')[-1]} - {len(df_adicional)} registros")
                except FileNotFoundError:
                    print(f"‚ö†Ô∏è  Dataset opcional no encontrado: {archivo.split('/')[-1]}")
            
            return True
            
        except FileNotFoundError:
            print("‚ùå Error: No se pudo cargar el dataset principal")
            return False
    
    def codificar_innovaciones_reales(self) -> Dict[str, np.ndarray]:
        """Codifica innovaciones reales en el espacio 9D del iuspace"""
        
        innovaciones_codificadas = {}
        
        if self.datos_innovaciones is not None:
            for _, row in self.datos_innovaciones.iterrows():
                nombre = row['innovation_name']
                
                # Usar mapeo predefinido si est√° disponible
                if nombre in self.mapeo_innovaciones:
                    vector = np.array(self.mapeo_innovaciones[nombre])
                else:
                    # Inferir coordenadas basadas en caracter√≠sticas
                    vector = self._inferir_coordenadas_iuspace(row)
                
                innovaciones_codificadas[nombre] = vector
        
        return innovaciones_codificadas
    
    def _inferir_coordenadas_iuspace(self, innovaci√≥n: pd.Series) -> np.ndarray:
        """Infiere coordenadas iuspace basadas en caracter√≠sticas de la innovaci√≥n"""
        
        # Algoritmo de inferencia basado en metadatos disponibles
        vector = np.ones(9) * 5  # Valor base neutral
        
        # 1. Formalismo - basado en el √°rea legal
        area_legal = str(innovaci√≥n.get('legal_area', '')).lower()
        if 'constitutional' in area_legal or 'criminal' in area_legal:
            vector[0] = 8  # Alto formalismo
        elif 'commercial' in area_legal or 'fintech' in area_legal:
            vector[0] = 4  # Bajo formalismo
        
        # 2. Centralizaci√≥n - basado en tipo de innovaci√≥n
        tipo = str(innovaci√≥n.get('innovation_type', '')).lower()
        if 'emergency' in tipo or 'crisis' in tipo:
            vector[1] = 8  # Alta centralizaci√≥n
        elif 'framework' in tipo or 'sandbox' in tipo:
            vector[1] = 3  # Baja centralizaci√≥n
        
        # 3. Codificaci√≥n - basado en nivel de adaptaci√≥n
        adaptaci√≥n = str(innovaci√≥n.get('adaptation_level', '')).lower()
        if adaptaci√≥n == 'low':
            vector[2] = 8  # Alta codificaci√≥n (menos adaptaci√≥n)
        elif adaptaci√≥n == 'substantial':
            vector[2] = 3  # Baja codificaci√≥n (m√°s adaptaci√≥n)
        
        # 4. Individualismo - basado en contexto
        if 'consumer' in area_legal or 'individual' in str(innovaci√≥n.get('innovation_type', '')):
            vector[3] = 7  # Alto individualismo
        elif 'collective' in str(innovaci√≥n.get('innovation_type', '')):
            vector[3] = 3  # Bajo individualismo
        
        # 5. Punitividad - basado en √°rea legal
        if 'criminal' in area_legal or 'liability' in str(innovaci√≥n.get('innovation_type', '')):
            vector[4] = 7  # Alta punitividad
        elif 'mediation' in str(innovaci√≥n.get('innovation_type', '')):
            vector[4] = 3  # Baja punitividad
        
        # 6. Complejidad procesal - basado en nivel de √©xito y adaptaci√≥n
        √©xito = str(innovaci√≥n.get('success_level', '')).lower()
        if √©xito == 'high' and adaptaci√≥n == 'low':
            vector[5] = 3  # Baja complejidad (f√°cil adopci√≥n)
        elif √©xito == 'low':
            vector[5] = 8  # Alta complejidad
        
        # 7. Integraci√≥n econ√≥mica - basado en √°rea legal
        if 'financial' in area_legal or 'monetary' in area_legal:
            vector[6] = 8  # Alta integraci√≥n econ√≥mica
        elif 'environmental' in area_legal or 'constitutional' in area_legal:
            vector[6] = 3  # Baja integraci√≥n econ√≥mica
        
        # 8. Internacionalizaci√≥n - basado en reconocimiento internacional
        reconocimiento = str(innovaci√≥n.get('international_recognition', '')).lower()
        if reconocimiento == 'high' or reconocimiento == 'very high':
            vector[7] = 8
        elif reconocimiento == 'low':
            vector[7] = 3
        
        # 9. Digitalizaci√≥n - basado en fecha y tipo
        fecha_origen = pd.to_datetime(innovaci√≥n.get('origin_date', '2000-01-01'))
        if fecha_origen.year >= 2015:
            vector[8] = 7  # Innovaciones recientes m√°s digitales
        elif 'digital' in str(innovaci√≥n.get('innovation_type', '')).lower():
            vector[8] = 9
        elif fecha_origen.year < 2000:
            vector[8] = 2  # Innovaciones antiguas menos digitales
        
        # Asegurar rango v√°lido [1, 10]
        vector = np.clip(vector, 1, 10)
        
        return vector
    
    def validar_familias_emergentes(self, resultado_experimento: Dict) -> Dict[str, Any]:
        """Valida si las familias legales emergentes coinciden con sistemas reales"""
        
        familias_emergentes = resultado_experimento.get('familias_emergentes', {})
        innovaciones_reales = self.codificar_innovaciones_reales()
        
        # Crear jusmorfos artificiales para las innovaciones reales
        jusmorfos_reales = []
        for nombre, vector in innovaciones_reales.items():
            gen_real = GenLegal(*vector.astype(int))
            jusmorfo_real = Jusmorfo(gen_real, nombre)
            jusmorfos_reales.append(jusmorfo_real)
        
        # Analizar distribuci√≥n de familias en datos reales
        familias_reales = {}
        for jusmorfo in jusmorfos_reales:
            familia = jusmorfo.familia_legal
            familias_reales[familia] = familias_reales.get(familia, 0) + 1
        
        # Comparar con familias emergentes del experimento
        familias_comunes = set(familias_emergentes.keys()) & set(familias_reales.keys())
        
        validaci√≥n = {
            'familias_experimento': familias_emergentes,
            'familias_datos_reales': familias_reales,
            'familias_coincidentes': list(familias_comunes),
            'porcentaje_coincidencia': len(familias_comunes) / len(familias_emergentes) * 100 if familias_emergentes else 0,
            'jusmorfos_reales_analizados': len(jusmorfos_reales)
        }
        
        return validaci√≥n
    
    def validar_ecuaci√≥n_fitness(self, resultado_experimento: Dict) -> Dict[str, Any]:
        """Valida la ecuaci√≥n de fitness contra datos reales de √©xito"""
        
        if self.datos_innovaciones is None:
            return {'error': 'No hay datos reales disponibles'}
        
        # Preparar datos para validaci√≥n
        innovaciones_reales = self.codificar_innovaciones_reales()
        
        predicciones_fitness = []
        √©xitos_reales = []
        
        for _, row in self.datos_innovaciones.iterrows():
            nombre = row['innovation_name']
            
            if nombre in innovaciones_reales:
                # Calcular fitness usando ecuaci√≥n del experimento
                vector = innovaciones_reales[nombre]
                gen_artificial = GenLegal(*vector.astype(int))
                
                # Crear neminem laedere como referencia
                neminem = GenLegal(1, 1, 1, 1, 1, 1, 1, 1, 1)
                distancia = gen_artificial.distancia_euclidiana(neminem)
                
                # Aplicar ecuaci√≥n: P(√©xito) = 0.92 * e^(-0.58 * distancia)
                fitness_predicho = 0.92 * np.exp(-0.58 * distancia / 10)  # Normalizado
                predicciones_fitness.append(fitness_predicho)
                
                # Mapear √©xito real a valor num√©rico
                √©xito_str = str(row.get('success_level', 'Medium')).lower()
                if √©xito_str == 'very high':
                    √©xito_num = 1.0
                elif √©xito_str == 'high':
                    √©xito_num = 0.8
                elif √©xito_str == 'medium':
                    √©xito_num = 0.6
                else:  # low
                    √©xito_num = 0.4
                
                √©xitos_reales.append(√©xito_num)
        
        # Calcular m√©tricas de validaci√≥n
        if predicciones_fitness and √©xitos_reales:
            predicciones_np = np.array(predicciones_fitness)
            √©xitos_np = np.array(√©xitos_reales)
            
            # Error absoluto medio
            mae = np.mean(np.abs(predicciones_np - √©xitos_np))
            
            # Coeficiente de correlaci√≥n
            correlaci√≥n = np.corrcoef(predicciones_np, √©xitos_np)[0, 1]
            
            # Precisi√≥n aproximada
            precisi√≥n = (1 - mae) * 100
            
            validaci√≥n = {
                'precisi√≥n_porcentaje': precisi√≥n,
                'correlaci√≥n': correlaci√≥n,
                'error_absoluto_medio': mae,
                'n_innovaciones_validadas': len(predicciones_fitness),
                'ecuaci√≥n_original': 'P(√©xito) = 0.92 * e^(-0.58 * distancia)',
                'interpretaci√≥n': self._interpretar_validaci√≥n(precisi√≥n, correlaci√≥n)
            }
        else:
            validaci√≥n = {'error': 'No se pudieron calcular m√©tricas de validaci√≥n'}
        
        return validaci√≥n
    
    def _interpretar_validaci√≥n(self, precisi√≥n: float, correlaci√≥n: float) -> str:
        """Interpreta los resultados de validaci√≥n"""
        
        if precisi√≥n >= 80 and correlaci√≥n >= 0.7:
            return "Validaci√≥n excelente: modelo muy predictivo"
        elif precisi√≥n >= 70 and correlaci√≥n >= 0.5:
            return "Validaci√≥n buena: modelo moderadamente predictivo"
        elif precisi√≥n >= 60 and correlaci√≥n >= 0.3:
            return "Validaci√≥n aceptable: modelo con capacidad predictiva limitada"
        else:
            return "Validaci√≥n d√©bil: modelo requiere mejoras significativas"
    
    def analizar_velocidades_evoluci√≥n(self, resultado_experimento: Dict) -> Dict[str, Any]:
        """Analiza velocidades de evoluci√≥n vs datos reales"""
        
        # Velocidad del experimento
        velocidad_experimento = resultado_experimento.get('velocidad_evoluci√≥n', 0)
        generaciones = resultado_experimento.get('generaciones_completadas', 1)
        
        # Calcular velocidades de difusi√≥n reales
        velocidades_reales = []
        
        if self.datos_innovaciones is not None:
            for _, row in self.datos_innovaciones.iterrows():
                if pd.notna(row['adoption_dates']):
                    fechas_adopci√≥n = row['adoption_dates'].split(',')
                    fecha_origen = pd.to_datetime(row['origin_date'])
                    
                    for fecha_str in fechas_adopci√≥n:
                        fecha_adopci√≥n = pd.to_datetime(fecha_str.strip())
                        a√±os_difusi√≥n = (fecha_adopci√≥n - fecha_origen).days / 365.25
                        if a√±os_difusi√≥n > 0:
                            velocidades_reales.append(1 / a√±os_difusi√≥n)  # Velocidad inversa
        
        # Comparaci√≥n
        if velocidades_reales:
            velocidad_real_promedio = np.mean(velocidades_reales)
            velocidad_real_mediana = np.median(velocidades_reales)
            
            # Factor de escala (generaciones por a√±o)
            factor_escala = 1  # Asumimos 1 generaci√≥n por a√±o como referencia
            velocidad_experimento_anualizada = velocidad_experimento * factor_escala
            
            comparaci√≥n = {
                'velocidad_experimento': velocidad_experimento,
                'velocidad_real_promedio': velocidad_real_promedio,
                'velocidad_real_mediana': velocidad_real_mediana,
                'factor_aceleraci√≥n_experimento': velocidad_experimento_anualizada / velocidad_real_promedio if velocidad_real_promedio > 0 else None,
                'n_difusiones_analizadas': len(velocidades_reales),
                'interpretaci√≥n': 'Experimento acelera evoluci√≥n vs realidad' if velocidad_experimento_anualizada > velocidad_real_promedio else 'Experimento refleja velocidad real'
            }
        else:
            comparaci√≥n = {'error': 'No hay datos suficientes de velocidades reales'}
        
        return comparaci√≥n
    
    def generar_reporte_validaci√≥n_completo(self, resultado_experimento: Dict) -> Dict[str, Any]:
        """Genera reporte completo de validaci√≥n emp√≠rica"""
        
        print("üî¨ INICIANDO VALIDACI√ìN EMP√çRICA")
        print("=" * 50)
        
        # Cargar datos reales
        datos_cargados = self.cargar_datos_reales()
        
        if not datos_cargados:
            return {'error': 'No se pudieron cargar los datos reales para validaci√≥n'}
        
        # Ejecutar todas las validaciones
        validaci√≥n_familias = self.validar_familias_emergentes(resultado_experimento)
        validaci√≥n_fitness = self.validar_ecuaci√≥n_fitness(resultado_experimento)
        validaci√≥n_velocidades = self.analizar_velocidades_evoluci√≥n(resultado_experimento)
        
        # Compilar reporte
        reporte_validaci√≥n = {
            'timestamp': pd.Timestamp.now().isoformat(),
            'tipo_validaci√≥n': 'EMP√çRICA COMPLETA',
            'datos_fuente': 'Dataset real multinacional de innovaciones legales',
            
            'validaci√≥n_familias_legales': validaci√≥n_familias,
            'validaci√≥n_ecuaci√≥n_fitness': validaci√≥n_fitness,
            'validaci√≥n_velocidades_evoluci√≥n': validaci√≥n_velocidades,
            
            'resumen_validaci√≥n': self._generar_resumen_validaci√≥n(
                validaci√≥n_familias, validaci√≥n_fitness, validaci√≥n_velocidades
            ),
            
            'recomendaciones_mejora': self._generar_recomendaciones(
                validaci√≥n_familias, validaci√≥n_fitness, validaci√≥n_velocidades
            )
        }
        
        return reporte_validaci√≥n
    
    def _generar_resumen_validaci√≥n(self, val_familias: Dict, val_fitness: Dict, val_velocidades: Dict) -> Dict[str, Any]:
        """Genera resumen ejecutivo de la validaci√≥n"""
        
        # Calcular puntaje general de validaci√≥n
        puntajes = []
        
        # Puntaje familias (0-100)
        if 'porcentaje_coincidencia' in val_familias:
            puntajes.append(val_familias['porcentaje_coincidencia'])
        
        # Puntaje fitness (0-100)
        if 'precisi√≥n_porcentaje' in val_fitness:
            puntajes.append(val_fitness['precisi√≥n_porcentaje'])
        
        # Puntaje velocidades (normalizado)
        if 'factor_aceleraci√≥n_experimento' in val_velocidades and val_velocidades['factor_aceleraci√≥n_experimento']:
            factor = val_velocidades['factor_aceleraci√≥n_experimento']
            # Normalizar: factor entre 0.5-2.0 es bueno (100 puntos)
            if 0.5 <= factor <= 2.0:
                puntaje_velocidad = 100
            elif factor < 0.5:
                puntaje_velocidad = factor * 200  # Escalar linealmente
            else:  # factor > 2.0
                puntaje_velocidad = max(0, 100 - (factor - 2) * 25)
            puntajes.append(puntaje_velocidad)
        
        puntaje_general = np.mean(puntajes) if puntajes else 0
        
        # Clasificaci√≥n de validaci√≥n
        if puntaje_general >= 80:
            clasificaci√≥n = "EXCELENTE"
        elif puntaje_general >= 70:
            clasificaci√≥n = "BUENA"
        elif puntaje_general >= 60:
            clasificaci√≥n = "ACEPTABLE"
        else:
            clasificaci√≥n = "D√âBIL"
        
        resumen = {
            'puntaje_general': puntaje_general,
            'clasificaci√≥n': clasificaci√≥n,
            'componentes_validados': len(puntajes),
            'fortalezas': self._identificar_fortalezas(val_familias, val_fitness, val_velocidades),
            'debilidades': self._identificar_debilidades(val_familias, val_fitness, val_velocidades)
        }
        
        return resumen
    
    def _identificar_fortalezas(self, val_familias: Dict, val_fitness: Dict, val_velocidades: Dict) -> List[str]:
        """Identifica fortalezas del modelo"""
        
        fortalezas = []
        
        if val_familias.get('porcentaje_coincidencia', 0) >= 70:
            fortalezas.append("Familias legales emergentes coinciden con datos reales")
        
        if val_fitness.get('precisi√≥n_porcentaje', 0) >= 70:
            fortalezas.append("Ecuaci√≥n de fitness es predictiva del √©xito real")
        
        if val_fitness.get('correlaci√≥n', 0) >= 0.5:
            fortalezas.append("Correlaci√≥n significativa entre predicci√≥n y realidad")
        
        if 'factor_aceleraci√≥n_experimento' in val_velocidades:
            factor = val_velocidades['factor_aceleraci√≥n_experimento']
            if factor and 0.8 <= factor <= 1.2:
                fortalezas.append("Velocidades de evoluci√≥n realistas")
        
        return fortalezas
    
    def _identificar_debilidades(self, val_familias: Dict, val_fitness: Dict, val_velocidades: Dict) -> List[str]:
        """Identifica debilidades del modelo"""
        
        debilidades = []
        
        if val_familias.get('porcentaje_coincidencia', 0) < 50:
            debilidades.append("Baja coincidencia en familias legales emergentes")
        
        if val_fitness.get('precisi√≥n_porcentaje', 0) < 60:
            debilidades.append("Ecuaci√≥n de fitness poco predictiva")
        
        if val_fitness.get('correlaci√≥n', 0) < 0.3:
            debilidades.append("Correlaci√≥n d√©bil entre predicci√≥n y realidad")
        
        if 'n_innovaciones_validadas' in val_fitness and val_fitness['n_innovaciones_validadas'] < 10:
            debilidades.append("Muestra peque√±a para validaci√≥n robusta")
        
        return debilidades
    
    def _generar_recomendaciones(self, val_familias: Dict, val_fitness: Dict, val_velocidades: Dict) -> List[str]:
        """Genera recomendaciones de mejora"""
        
        recomendaciones = []
        
        if val_familias.get('porcentaje_coincidencia', 0) < 70:
            recomendaciones.append("Ajustar algoritmo de clasificaci√≥n de familias legales")
        
        if val_fitness.get('precisi√≥n_porcentaje', 0) < 70:
            recomendaciones.append("Recalibrar par√°metros Œ± y Œ≤ de la ecuaci√≥n de fitness")
        
        if val_fitness.get('n_innovaciones_validadas', 0) < 20:
            recomendaciones.append("Expandir dataset de validaci√≥n con m√°s innovaciones codificadas")
        
        recomendaciones.append("Implementar validaci√≥n cruzada con datos de otros pa√≠ses")
        recomendaciones.append("Agregar dimensiones del iuspace espec√≠ficas para capturar m√°s variaci√≥n")
        
        return recomendaciones

def ejecutar_validaci√≥n_completa(archivo_resultado: str):
    """Ejecuta validaci√≥n completa de un experimento de biomorfos legales"""
    
    print("üî¨ VALIDACI√ìN EMP√çRICA DE BIOMORFOS LEGALES")
    print("=" * 60)
    
    try:
        # Cargar resultado del experimento
        with open(archivo_resultado, 'r', encoding='utf-8') as f:
            resultado_experimento = json.load(f)
        
        print(f"‚úÖ Resultado cargado: {archivo_resultado}")
        
        # Crear validador
        validador = ValidadorEmp√≠rico()
        
        # Ejecutar validaci√≥n completa
        reporte_validaci√≥n = validador.generar_reporte_validaci√≥n_completo(resultado_experimento)
        
        # Guardar reporte de validaci√≥n
        timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
        filename_validaci√≥n = f"validacion_empirica_{timestamp}.json"
        
        with open(filename_validaci√≥n, 'w', encoding='utf-8') as f:
            json.dump(reporte_validaci√≥n, f, ensure_ascii=False, indent=2)
        
        # Mostrar resumen
        print("\n" + "=" * 60)
        print("üìä RESUMEN DE VALIDACI√ìN EMP√çRICA")
        print("=" * 60)
        
        resumen = reporte_validaci√≥n.get('resumen_validaci√≥n', {})
        print(f"Puntaje general: {resumen.get('puntaje_general', 0):.1f}%")
        print(f"Clasificaci√≥n: {resumen.get('clasificaci√≥n', 'N/A')}")
        print(f"Componentes validados: {resumen.get('componentes_validados', 0)}")
        
        print(f"\nFortalezas identificadas:")
        for fortaleza in resumen.get('fortalezas', []):
            print(f"  ‚Ä¢ {fortaleza}")
        
        print(f"\n√Åreas de mejora:")
        for debilidad in resumen.get('debilidades', []):
            print(f"  ‚Ä¢ {debilidad}")
        
        print(f"\nReporte guardado: {filename_validaci√≥n}")
        
        return reporte_validaci√≥n
        
    except FileNotFoundError:
        print(f"‚ùå Error: No se encontr√≥ el archivo {archivo_resultado}")
        return None
    except Exception as e:
        print(f"‚ùå Error durante la validaci√≥n: {e}")
        return None

if __name__ == "__main__":
    # Demo de validaci√≥n
    print("Demo de validaci√≥n emp√≠rica disponible")
    print("Para ejecutar: ejecutar_validaci√≥n_completa('archivo_resultado_experimento.json')")